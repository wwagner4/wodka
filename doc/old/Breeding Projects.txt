Breeding Projects

----------------------------------------------------------------------------------------------------------------------
Jumping Triangles

Originator: StefW
Threads: Jumping Triangles, Evolutionary programming

The optimization program starts with a template of a model and then generates XML files based on this 
template. 
 
The optimization method I use is called "evolutionary programming", which is similar to genetic programming 
but without crossover. The population size I used is 100 models. 
 
The algorithm works as follows: 
 
1. Initialize the initial population by reading the template model from disk. 
2. Evaluate the models in the population. 
3. Select 5 random models from the population. 
4. From these 5 models, select the best and the worst model (this is called tournament selection). 
5. Replace the parameters of the worst model with the parameters of the best model and add a small 
random change. 
6. This random change consists of randomly selecting one parameter, and adding a normally distributed 
random number to it. For the spring lengths, muscle lengths, mass position and velocity, the standard 
deviation is 1.0. For all other parameters, the standard deviation is 0.01. 
7. Evaluate the newly created model. 
8. Goto 3 
 
Tests with different kinds of models (amoebas and dainty walkers) show that it works very well for different 
kinds of models. 
 
The race shows an optimized amoeba on the mountain race, which was generated by the algorithm after 200 
generations.













----------------------------------------------------------------------------------------------------------------------
Jbrownlee's

Originator: jbrownlee
Threads: Evolving Models from scratch - Hows it all going ?

I'm going for the connection focused approach, where connections are evolved 
between masses. Its based on genetic algorithms used to evolve away connections in 
neural networks














----------------------------------------------------------------------------------------------------------------------
Optimised Dainty Walker
	
Originator: RiMano, (Chirag same Team)
Threads: Optimised Dainty Walker

Is using a searching technique called simulated annealing. Basically simulated annealing is an algorithm for searching solution within a problem, in this case the fastest model, working from a base model. There will be an in-depth explanation about the process, when I eventually get a website going.














----------------------------------------------------------------------------------------------------------------------
Ameobas

Originator: Chirag
Threads: Ameobas created with a genetic algorithm

using an "AmeobaFactory" class that takes in a set of parameters and generates an ameoba, our algorithm does the following

1. Create a population of randomly generated ameobas.
2. Test the fitness of each ameoba.
3. Select two ameobas from this population (favouring the fastest ones) and perform a crossover of the parameters to create a new ameoba.
4. Mutate the parameters of the newly created ameoba.
5. test the fitness of this ameoba. If it turns out to be faster than any of the ameobas in the population. Throw out the slowest ameoba and add this one to the population. Go to step 3
The crossover basically works by taking parameters from 2 ameobas and combining them to make a new ameoba.
The mutation just changes a parameter by some random amount.
Ok i admit this all may seem a bit confusing., but hopefully we'll have a website up soon so we can explain how we did this properly plus make our source code available to anyone needing help in creating there own intelligent modellers. 
In the meanwhile try beat this one... this race is for ameobas only! 














